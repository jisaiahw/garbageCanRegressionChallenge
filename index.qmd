---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---


**Using R for the analysis.**

## R Code

```{r}
#| echo: false
library(tidyverse)
library(broom)

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
observDF <- tribble(
  ~Stress, ~StressSurvey, ~Time, ~Anxiety,
  0,0,0,0,
  0,0,1,0.1,
  0,0,1,0.1,
  1,3,1,1.1,
  1,3,1,1.1,
  1,3,1,1.1,
  2,6,2,2.2,
  2,6,2,2.2,
  2,6,2,2.2,
  8,9,2,8.2,
  8,9,2,8.2,
  8,9,2.1,8.21,
  12,12,2.2,12.22,
  12,12,2.2,12.22,
  12,12,2.2,12.22
)

observDF
```


## Your Analysis

# 1. Bivariate Regression Analysis with StressSurvey

```{r}
model1 <- lm(Anxiety ~ StressSurvey, data = observDF)
tidy(model1)
```

**Estimated Coefficients:** 
- **Intercept**: The estimated intercept value
- **StressSurvey coefficient**: 1.05

**Comparison to True Relationship:**
The true relationship is: **Anxiety = Stress + 0.1 × Time**

- **True Stress coefficient**: 1.0
- **Estimated StressSurvey coefficient**: 1.05
- **Bias**: +0.05 (5% upward bias)

The estimated coefficient of **1.05** is close to the true coefficient of **1.0**, showing that StressSurvey is a good proxy for the true Stress variable. However, the slight upward bias occurs because the omitted Time variable's effect gets absorbed into the StressSurvey coefficient.

# 2. Visualization of Bivariate Relationship
```{r}
ggplot(observDF, aes(x = StressSurvey, y = Anxiety)) +
  geom_point(size = 3, color = "purple") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Bivariate Regression: Anxiety ~ StressSurvey",
       x = "Stress Survey",
       y = "Anxiety") +
  theme_minimal()
```
The scatterplot shows Anxiety increasing with StressSurvey. The regression line appears to fit well overall, but careful inspection reveals “kinks” where StressSurvey does not map linearly to Stress. This is a subtle but dangerous source of bias: the regression looks good but tells the wrong story about effect sizes.

# 3. Bivariate Regression Analysis with Time
```{r}
model2 <- lm(Anxiety ~ Time, data = observDF)
tidy(model2)
```
The estimated coefficient is 5.34, which is far from the true coefficient of 0.1. Additionally, the intercept is -3.68, which is far from the true intercept of 0.

# 4A. Visualization of Bivariate Relationship
```{r}
ggplot(observDF, aes(x = Time, y = Anxiety)) +
  geom_point(size = 3, color = "blue") +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  labs(title = "Bivariate Regression: Anxiety ~ Time",
       x = "Time on Social Media",
       y = "Anxiety") +
  theme_minimal()
```
The scatterplot shows Anxiety increasing with Time. The regression line appears to fit well overall, but careful inspection reveals “kinks” where Time does not map linearly to Anxiety. This is a subtle but dangerous source of bias: the regression looks good but tells the wrong story about effect sizes.

# 5A. Multiple Regression Analysis
```{r}
model3 <- lm(Anxiety ~ StressSurvey + Time, data = observDF)
tidy(model3)
```
The estimated coefficients of StressSurvey and time are 1.43 and -2.78, respectively. StressSurvey indicates a 43% spike in anxiety for every unit increase in StressSurvey, while Time indicates a 278% decrease in anxiety for every unit increase in Time. This does not reflect the true relationships between stress, time, and anxiety. Stress does have a positive correlation with anxiety, but not by that much. Time is not supposed to have a negative correlation with anxiety, but this model suggests that it does, with almost 28 times more effect than the true relationship.

# 4B. Multiple Regression Analysis
```{r}
model4 <- lm(Anxiety ~ Stress + Time, data = observDF)
tidy(model4)
```
The estimated coefficients for Stress and Time are 1 and 0.1, respectively, which are about the same as the true coefficients.

# 5B. Model Comparison
```{r}
glance(model3)
glance(model4)
```
Both models have high R² values, but only the model using Stress (not StressSurvey) gives coefficients that match the true causal process. The illusion of fit from the StressSurvey model shows why researchers must be skeptical: a high R² does not guarantee correct interpretation. This is the essence of the “garbage can regression” problem.

# 6. Reflect on Real-World Implications
If the respective outputs of the two multiple regression models were published in academic journals and picked up by the popular press, the first model would imply that stress has a more dramatic impact on anxiety and that time spent on social media reduces anxiety. The second model suggests that both stress and time increase anxiety.
A concerned parent worried about their child's social media usage would likely be more responsive to the first model, while executives of social media companies would likely prefer the second model.

# 7. Avoiding Misleading Statistical Significance
By analyzing a smartly chosen subset of the data, we can avoid being misled by "statistically significant" results.
```{r}
# Low stress subset
low_subset <- observDF %>% filter(Stress <= 6)
model_low <- lm(Anxiety ~ StressSurvey + Time, data = low_subset)
tidy(model_low)

# High stress subset
high_subset <- observDF %>% filter(Stress > 6)
model_high <- lm(Anxiety ~ StressSurvey + Time, data = high_subset)
tidy(model_high)
```
I chose to split the data into low and high stress subsets because the StressSurvey results are triple the true Stress results until StressSurvey exceeds 6, in addition to 6 being half of the maximum stress level of 12. The results are statistically significant, but only some of the coefficients match the true coefficients.

