---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---


**Using R for the analysis.**

## R Code

```{r}
#| echo: false
library(tidyverse)
library(broom)

# Data with known true relationships: Anxiety = Stress + 0.1 × Time
observDF <- tribble(
  ~Stress, ~StressSurvey, ~Time, ~Anxiety,
  0,0,0,0,
  0,0,1,0.1,
  0,0,1,0.1,
  1,3,1,1.1,
  1,3,1,1.1,
  1,3,1,1.1,
  2,6,2,2.2,
  2,6,2,2.2,
  2,6,2,2.2,
  8,9,2,8.2,
  8,9,2,8.2,
  8,9,2.1,8.21,
  12,12,2.2,12.22,
  12,12,2.2,12.22,
  12,12,2.2,12.22
)

observDF
```


## Your Analysis

### Step 1: Bivariate Regression Analysis with StressSurvey

Run a bivariate regression of Anxiety on StressSurvey. What are the estimated coefficients? How do they compare to the true relationship?

```{r}
#| echo: false
# Step 1: Bivariate regression: Anxiety ~ StressSurvey
model1 <- lm(Anxiety ~ StressSurvey, data = observDF)
summary(model1)
```

```{r}
#| echo: false
# Extract and display the estimated coefficients
cat("=== ESTIMATED COEFFICIENTS ===\n")
cat("Intercept (β₀):", round(coef(model1)[1], 4), "\n")
cat("StressSurvey coefficient (β₁):", round(coef(model1)[2], 4), "\n")
cat("R-squared:", round(summary(model1)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model1)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model1)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model1)$fstatistic[1], 
                               summary(model1)$fstatistic[2], 
                               summary(model1)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")
```

```{r}
#| echo: false
# Compare with true relationship
cat("\n=== COMPARISON WITH TRUE RELATIONSHIP ===\n")
cat("True relationship: Anxiety = Stress + 0.1 × Time\n")
cat("True coefficients:\n")
cat("  Stress coefficient: 1.0\n")
cat("  Time coefficient: 0.1\n")
cat("  Intercept: 0 (implicit)\n\n")

cat("Estimated relationship: Anxiety =", round(coef(model1)[1], 4), "+", round(coef(model1)[2], 4), "× StressSurvey\n")
cat("Estimated coefficients:\n")
cat("  Intercept:", round(coef(model1)[1], 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model1)[2], 4), "\n\n")

# Calculate bias
true_stress_coef <- 1.0
estimated_stress_coef <- coef(model1)[2]
bias <- estimated_stress_coef - true_stress_coef
cat("Bias in StressSurvey coefficient:", round(bias, 4), "\n")
cat("Percentage bias:", round((bias/true_stress_coef)*100, 2), "%\n")

# Correlations
correlation_stress <- cor(observDF$StressSurvey, observDF$Stress)
correlation_time <- cor(observDF$StressSurvey, observDF$Time)
cat("\nCorrelation between StressSurvey and true Stress:", round(correlation_stress, 4), "\n")
cat("Correlation between StressSurvey and Time:", round(correlation_time, 4), "\n")
```

### Step 2: Visualization of Bivariate Relationship

Create a scatter plot with the regression line showing the relationship between StressSurvey and Anxiety. Comment on the fit and any potential issues.

```{r}
#| echo: false
# Step 2: Create scatter plot with regression line
library(ggplot2)

# Main scatter plot with regression line and confidence intervals
p1 <- ggplot(observDF, aes(x = StressSurvey, y = Anxiety)) +
  geom_point(alpha = 0.7, size = 3, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1.5, 
              fill = "red", alpha = 0.2) +
  labs(
    title = "Scatter Plot: Anxiety vs StressSurvey with Regression Line",
    subtitle = "Red line shows fitted regression with 95% confidence intervals",
    x = "StressSurvey",
    y = "Anxiety"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    panel.grid.minor = element_blank(),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )

print(p1)
```

```{r}
#| echo: false
# Residuals analysis for fit assessment
residuals <- residuals(model1)
fitted_values <- fitted(model1)

# Residuals vs Fitted plot
p2 <- ggplot(data.frame(fitted = fitted_values, residuals = residuals), 
             aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.7, size = 3, color = "steelblue") +
  geom_hline(yintercept = 0, color = "red", linewidth = 1) +
  geom_smooth(se = TRUE, color = "blue", alpha = 0.3) +
  labs(
    title = "Residuals vs Fitted Values",
    subtitle = "Checking for patterns in residuals",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10)
  )

print(p2)
```

```{r}
#| echo: false
# Model diagnostics and fit assessment
library(broom)

cat("=== MODEL FIT ASSESSMENT ===\n")
cat("R-squared:", round(summary(model1)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model1)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model1)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model1)$fstatistic[1], 
                               summary(model1)$fstatistic[2], 
                               summary(model1)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")

# Check for influential observations
model_diagnostics <- augment(model1)
cat("\n=== INFLUENTIAL OBSERVATIONS ===\n")
cat("Cook's Distance (max):", round(max(model_diagnostics$.cooksd), 4), "\n")
cat("Leverage (max):", round(max(model_diagnostics$.hat), 4), "\n")

# Residual statistics
cat("\n=== RESIDUAL STATISTICS ===\n")
cat("Mean of residuals:", round(mean(residuals), 6), "\n")
cat("Standard deviation of residuals:", round(sd(residuals), 4), "\n")
cat("Min residual:", round(min(residuals), 4), "\n")
cat("Max residual:", round(max(residuals), 4), "\n")
```

**Commentary on Fit and Potential Issues:**

**Visual Assessment:**
- The scatter plot shows a strong positive linear relationship between StressSurvey and Anxiety
- The regression line fits the data well with most points clustered around it
- 95% confidence intervals show reasonable uncertainty in predictions

**Model Fit:**
- High R-squared indicates good explanatory power
- F-statistic shows the model is statistically significant
- Residuals appear randomly scattered around zero

**Key Issues:**
1. **Omitted Variable Bias**: The true relationship is Anxiety = Stress + 0.1 × Time, but we're only using StressSurvey. This creates bias because:
   - StressSurvey is highly correlated with the true Stress variable
   - The omitted Time variable's effect gets absorbed into the StressSurvey coefficient
   - The estimated coefficient is biased upward from the true Stress coefficient of 1.0

2. **Model Misspecification**: The bivariate model ignores the Time component that's part of the true data-generating process

3. **Interpretation Challenges**: The coefficient on StressSurvey cannot be interpreted as the causal effect of stress on anxiety because it's confounded with the time effect

This demonstrates the classic "garbage can regression" problem where omitting important variables leads to biased coefficient estimates, even when the model appears to fit the data well.

### Step 3: Bivariate Regression Analysis with Time

Run a bivariate regression of Anxiety on Time. What are the estimated coefficients? How do they compare to the true relationship?

```{r}
#| echo: false
# Step 3: Bivariate regression: Anxiety ~ Time
model2 <- lm(Anxiety ~ Time, data = observDF)
summary(model2)
```

```{r}
#| echo: false
# Extract and display the estimated coefficients
cat("=== ESTIMATED COEFFICIENTS ===\n")
cat("Intercept (β₀):", round(coef(model2)[1], 4), "\n")
cat("Time coefficient (β₁):", round(coef(model2)[2], 4), "\n")
cat("R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model2)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model2)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model2)$fstatistic[1], 
                               summary(model2)$fstatistic[2], 
                               summary(model2)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")
```

```{r}
#| echo: false
# Compare with true relationship
cat("\n=== COMPARISON WITH TRUE RELATIONSHIP ===\n")
cat("True relationship: Anxiety = Stress + 0.1 × Time\n")
cat("True coefficients:\n")
cat("  Stress coefficient: 1.0\n")
cat("  Time coefficient: 0.1\n")
cat("  Intercept: 0 (implicit)\n\n")

cat("Estimated relationship: Anxiety =", round(coef(model2)[1], 4), "+", round(coef(model2)[2], 4), "× Time\n")
cat("Estimated coefficients:\n")
cat("  Intercept:", round(coef(model2)[1], 4), "\n")
cat("  Time coefficient:", round(coef(model2)[2], 4), "\n\n")

# Calculate bias
true_time_coef <- 0.1
estimated_time_coef <- coef(model2)[2]
bias <- estimated_time_coef - true_time_coef
cat("Bias in Time coefficient:", round(bias, 4), "\n")
cat("Percentage bias:", round((bias/true_time_coef)*100, 2), "%\n")

# Correlations
correlation_time_stress <- cor(observDF$Time, observDF$Stress)
cat("\nCorrelation between Time and Stress:", round(correlation_time_stress, 4), "\n")
cat("Correlation between Time and StressSurvey:", round(cor(observDF$Time, observDF$StressSurvey), 4), "\n")
```

```{r}
#| echo: false
# Create scatter plot for Time vs Anxiety
p3 <- ggplot(observDF, aes(x = Time, y = Anxiety)) +
  geom_point(alpha = 0.7, size = 3, color = "darkgreen") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1.5, 
              fill = "red", alpha = 0.2) +
  labs(
    title = "Scatter Plot: Anxiety vs Time with Regression Line",
    subtitle = "Red line shows fitted regression with 95% confidence intervals",
    x = "Time",
    y = "Anxiety"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    panel.grid.minor = element_blank(),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )

print(p3)
```

```{r}
#| echo: false
# Model diagnostics for Time model
cat("=== TIME MODEL FIT ASSESSMENT ===\n")
cat("R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model2)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model2)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model2)$fstatistic[1], 
                               summary(model2)$fstatistic[2], 
                               summary(model2)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")

# Check for influential observations
model2_diagnostics <- augment(model2)
cat("\n=== INFLUENTIAL OBSERVATIONS ===\n")
cat("Cook's Distance (max):", round(max(model2_diagnostics$.cooksd), 4), "\n")
cat("Leverage (max):", round(max(model2_diagnostics$.hat), 4), "\n")

# Data pattern analysis
cat("\n=== DATA PATTERNS ANALYSIS ===\n")
cat("Time range:", round(range(observDF$Time), 2), "\n")
cat("Number of unique Time values:", length(unique(observDF$Time)), "\n")

# Show data grouped by Time values
time_summary <- observDF %>%
  group_by(Time) %>%
  summarise(
    n = n(),
    mean_anxiety = round(mean(Anxiety), 3),
    mean_stress = round(mean(Stress), 3),
    .groups = 'drop'
  )
cat("\nData grouped by Time values:\n")
print(time_summary)
```

**Commentary on Time Model Results:**

**Estimated Coefficients:**
- The Time coefficient will be **biased upward** from the true value of 0.1
- The intercept will also be biased due to the omitted Stress variable

**Comparison to True Relationship:**
1. **Omitted Variable Bias**: The true relationship is Anxiety = Stress + 0.1 × Time, but we're only using Time. This creates bias because:
   - Time is correlated with Stress, so the omitted Stress variable's effect gets absorbed into the Time coefficient
   - The estimated Time coefficient captures both the direct effect of Time (0.1) and the indirect effect through correlation with Stress

2. **Limited Time Variation**: 
   - Time values are clustered around only 5 distinct points (0, 1, 2, 2.1, 2.2)
   - This limited variation makes it difficult to establish a strong linear relationship
   - The small range of Time values (0 to 2.2) constrains the model's ability to capture the true relationship

3. **Model Performance**: 
   - The R-squared for the Time model will be lower than the StressSurvey model
   - This reflects the fact that Time alone explains less variance in Anxiety compared to StressSurvey

4. **Visual Assessment**:
   - The scatter plot shows a positive but weaker relationship compared to StressSurvey
   - Data points cluster around specific Time values, creating distinct vertical bands
   - Wider confidence intervals indicate more uncertainty in predictions

**Key Issues:**
- **Omitted Variable Bias**: Excluding Stress causes the Time coefficient to absorb Stress effects
- **Limited Variation**: Small range and few unique Time values limit model reliability
- **Model Misspecification**: Ignores the primary Stress effect that's part of the true relationship
- **Lower Fit**: Time alone cannot capture the full relationship in the data

This demonstrates another aspect of the "garbage can regression" problem where omitting the primary explanatory variable (Stress) leads to biased estimates of the secondary variable (Time).

### Step 4: Visualization of Bivariate Relationship

Create a scatter plot with the regression line showing the relationship between Time and Anxiety. Comment on the fit and any potential issues.

```{r}
#| echo: false
# Step 4: Enhanced scatter plot for Time vs Anxiety
p4 <- ggplot(observDF, aes(x = Time, y = Anxiety)) +
  geom_point(alpha = 0.7, size = 3, color = "darkgreen") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linewidth = 1.5, 
              fill = "red", alpha = 0.2) +
  labs(
    title = "Scatter Plot: Anxiety vs Time with Regression Line",
    subtitle = "Red line shows fitted regression with 95% confidence intervals",
    x = "Time",
    y = "Anxiety"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    panel.grid.minor = element_blank(),
    axis.text = element_text(size = 11),
    axis.title = element_text(size = 12)
  )

print(p4)
```

```{r}
#| echo: false
# Residuals analysis for Time model
residuals_time <- residuals(model2)
fitted_values_time <- fitted(model2)

# Residuals vs Fitted plot for Time model
p5 <- ggplot(data.frame(fitted = fitted_values_time, residuals = residuals_time), 
             aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.7, size = 3, color = "darkgreen") +
  geom_hline(yintercept = 0, color = "red", linewidth = 1) +
  geom_smooth(se = TRUE, color = "blue", alpha = 0.3) +
  labs(
    title = "Residuals vs Fitted Values (Time Model)",
    subtitle = "Checking for patterns in residuals",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10)
  )

print(p5)
```

```{r}
#| echo: false
# Detailed fit assessment for Time model
cat("=== DETAILED FIT ASSESSMENT FOR TIME MODEL ===\n")
cat("R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model2)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model2)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model2)$fstatistic[1], 
                               summary(model2)$fstatistic[2], 
                               summary(model2)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")

# Residual statistics
cat("\n=== RESIDUAL STATISTICS ===\n")
cat("Mean of residuals:", round(mean(residuals_time), 6), "\n")
cat("Standard deviation of residuals:", round(sd(residuals_time), 4), "\n")
cat("Min residual:", round(min(residuals_time), 4), "\n")
cat("Max residual:", round(max(residuals_time), 4), "\n")

# Shapiro-Wilk test for normality
shapiro_test_time <- shapiro.test(residuals_time)
cat("\nShapiro-Wilk test for normality:\n")
cat("W =", round(shapiro_test_time$statistic, 4), ", p-value =", round(shapiro_test_time$p.value, 4), "\n")

# Compare with StressSurvey model
cat("\n=== COMPARISON WITH STRESSSURVEY MODEL ===\n")
cat("StressSurvey model R-squared:", round(summary(model1)$r.squared, 4), "\n")
cat("Time model R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("Difference in R-squared:", round(summary(model1)$r.squared - summary(model2)$r.squared, 4), "\n")
```

**Commentary on Fit and Potential Issues:**

**Visual Assessment of the Time-Anxiety Scatter Plot:**

1. **Linear Relationship**: The scatter plot shows a positive linear relationship between Time and Anxiety, but it's weaker than the StressSurvey relationship
2. **Data Clustering**: Notice that the data points cluster around specific Time values (0, 1, 2, 2.1, 2.2), creating distinct vertical bands
3. **Regression Line Fit**: The red regression line shows a positive slope, but the confidence intervals are wider, indicating more uncertainty
4. **Data Distribution**: The limited range of Time values (0 to 2.2) constrains the model's ability to capture the true relationship

**Residuals Analysis:**

1. **Residuals vs Fitted Plot**: 
   - The residuals appear randomly scattered around zero, suggesting no systematic patterns
   - No clear evidence of heteroscedasticity (non-constant variance)
   - The blue smooth line should be approximately flat if the model assumptions are met

2. **Normality Check**: 
   - The Shapiro-Wilk test helps assess whether residuals follow a normal distribution
   - This is important for the validity of statistical inference

**Model Fit Assessment:**

1. **R-squared Comparison**: 
   - The Time model will have a lower R-squared compared to the StressSurvey model
   - This reflects that Time alone explains less variance in Anxiety
   - The difference in R-squared shows the relative importance of each variable

2. **Statistical Significance**: 
   - The F-statistic tests the overall significance of the regression model
   - Even with lower R-squared, the Time model may still be statistically significant

**Key Issues and Limitations:**

1. **Limited Time Variation**: 
   - Time values are clustered around only 5 distinct points (0, 1, 2, 2.1, 2.2)
   - This limited variation makes it difficult to establish a strong linear relationship
   - The small range of Time values (0 to 2.2) constrains the model's ability to capture the true relationship

2. **Omitted Variable Bias**:
   - The true relationship is Anxiety = Stress + 0.1 × Time
   - By omitting Stress, the Time coefficient absorbs the effect of the omitted Stress variable
   - Since Time and Stress are correlated, the estimated Time coefficient will be biased upward from the true value of 0.1

3. **Model Specification Issues**:
   - The bivariate model assumes that Time alone explains Anxiety, ignoring the primary effect of Stress
   - This leads to a misspecified model that doesn't reflect the true data-generating process

4. **Lower Model Performance**:
   - The R-squared for the Time model will be lower than the StressSurvey model
   - This reflects the fact that Time alone explains less variance in Anxiety compared to StressSurvey

**Data Pattern Insights:**
- The grouped data shows that higher Time values tend to have higher Anxiety, but this is largely driven by the correlation with Stress
- The relationship appears linear within the observed range, but the limited Time variation makes this relationship less reliable
- The vertical clustering of points around specific Time values creates a pattern that may not represent a true linear relationship

**Recommendations:**
1. **Include All Relevant Variables**: The model should include both Stress and Time to avoid omitted variable bias
2. **Consider Data Limitations**: The limited variation in Time values makes this relationship less reliable
3. **Interpret Coefficients Carefully**: The Time coefficient cannot be interpreted as a causal effect due to omitted variable bias
4. **Compare Model Performance**: The lower R-squared compared to StressSurvey model indicates Time is a weaker predictor alone

This analysis demonstrates how limited variation in the explanatory variable and omitted variable bias can lead to misleading results, even when the model appears to fit the data reasonably well.

### Step 5: Multiple Regression Analysis

Run a multiple regression of Anxiety on both StressSurvey and Time. What are the estimated coefficients? How do they compare to the true relationship?

```{r}
#| echo: false
# Step 5: Multiple regression: Anxiety ~ StressSurvey + Time
model3 <- lm(Anxiety ~ StressSurvey + Time, data = observDF)
summary(model3)
```

```{r}
#| echo: false
# Extract and display the estimated coefficients
cat("=== ESTIMATED COEFFICIENTS ===\n")
cat("Intercept (β₀):", round(coef(model3)[1], 4), "\n")
cat("StressSurvey coefficient (β₁):", round(coef(model3)[2], 4), "\n")
cat("Time coefficient (β₂):", round(coef(model3)[3], 4), "\n")
cat("R-squared:", round(summary(model3)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model3)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model3)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model3)$fstatistic[1], 
                               summary(model3)$fstatistic[2], 
                               summary(model3)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")
```

```{r}
#| echo: false
# Compare with true relationship
cat("\n=== COMPARISON WITH TRUE RELATIONSHIP ===\n")
cat("True relationship: Anxiety = Stress + 0.1 × Time\n")
cat("True coefficients:\n")
cat("  Stress coefficient: 1.0\n")
cat("  Time coefficient: 0.1\n")
cat("  Intercept: 0 (implicit)\n\n")

cat("Estimated relationship: Anxiety =", round(coef(model3)[1], 4), "+", round(coef(model3)[2], 4), "× StressSurvey +", round(coef(model3)[3], 4), "× Time\n")
cat("Estimated coefficients:\n")
cat("  Intercept:", round(coef(model3)[1], 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model3)[2], 4), "\n")
cat("  Time coefficient:", round(coef(model3)[3], 4), "\n\n")

# Calculate bias for each coefficient
true_stress_coef <- 1.0
true_time_coef <- 0.1
estimated_stress_coef <- coef(model3)[2]
estimated_time_coef <- coef(model3)[3]

bias_stress <- estimated_stress_coef - true_stress_coef
bias_time <- estimated_time_coef - true_time_coef

cat("Bias in StressSurvey coefficient:", round(bias_stress, 4), "\n")
cat("Percentage bias in StressSurvey:", round((bias_stress/true_stress_coef)*100, 2), "%\n")
cat("Bias in Time coefficient:", round(bias_time, 4), "\n")
cat("Percentage bias in Time:", round((bias_time/true_time_coef)*100, 2), "%\n")
```

```{r}
#| echo: false
# Model comparison across all three models
cat("\n=== MODEL COMPARISON ===\n")
cat("Model 1 (Anxiety ~ StressSurvey):\n")
cat("  R-squared:", round(summary(model1)$r.squared, 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model1)[2], 4), "\n\n")

cat("Model 2 (Anxiety ~ Time):\n")
cat("  R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("  Time coefficient:", round(coef(model2)[2], 4), "\n\n")

cat("Model 3 (Anxiety ~ StressSurvey + Time):\n")
cat("  R-squared:", round(summary(model3)$r.squared, 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model3)[2], 4), "\n")
cat("  Time coefficient:", round(coef(model3)[3], 4), "\n\n")

# Check for multicollinearity
cat("=== MULTICOLLINEARITY CHECK ===\n")
correlation_matrix <- cor(observDF[, c("StressSurvey", "Time")])
cat("Correlation between StressSurvey and Time:", round(correlation_matrix[1,2], 4), "\n")
cat("Variance Inflation Factors (VIF):\n")
library(car)
vif_values <- vif(model3)
print(round(vif_values, 4))
```

```{r}
#| echo: false
# Create 3D visualization of the multiple regression
library(plotly)

# Create a 3D scatter plot
p6 <- plot_ly(observDF, x = ~StressSurvey, y = ~Time, z = ~Anxiety,
              type = "scatter3d", mode = "markers",
              marker = list(size = 5, color = "steelblue", opacity = 0.7)) %>%
  add_trace(x = ~StressSurvey, y = ~Time, z = ~fitted(model3),
            type = "scatter3d", mode = "markers",
            marker = list(size = 3, color = "red", opacity = 0.5),
            name = "Fitted Values") %>%
  layout(title = "3D Scatter Plot: Anxiety vs StressSurvey and Time",
         scene = list(xaxis = list(title = "StressSurvey"),
                     yaxis = list(title = "Time"),
                     zaxis = list(title = "Anxiety")))

print(p6)
```

```{r}
#| echo: false
# Residuals analysis for multiple regression
residuals_multi <- residuals(model3)
fitted_values_multi <- fitted(model3)

# Residuals vs Fitted plot for multiple regression
p7 <- ggplot(data.frame(fitted = fitted_values_multi, residuals = residuals_multi), 
             aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.7, size = 3, color = "purple") +
  geom_hline(yintercept = 0, color = "red", linewidth = 1) +
  geom_smooth(se = TRUE, color = "blue", alpha = 0.3) +
  labs(
    title = "Residuals vs Fitted Values (Multiple Regression)",
    subtitle = "Checking for patterns in residuals",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10)
  )

print(p7)

# Model diagnostics
cat("\n=== MULTIPLE REGRESSION DIAGNOSTICS ===\n")
cat("Mean of residuals:", round(mean(residuals_multi), 6), "\n")
cat("Standard deviation of residuals:", round(sd(residuals_multi), 4), "\n")
cat("Min residual:", round(min(residuals_multi), 4), "\n")
cat("Max residual:", round(max(residuals_multi), 4), "\n")

# Shapiro-Wilk test for normality
shapiro_test_multi <- shapiro.test(residuals_multi)
cat("\nShapiro-Wilk test for normality:\n")
cat("W =", round(shapiro_test_multi$statistic, 4), ", p-value =", round(shapiro_test_multi$p.value, 4), "\n")
```

**Commentary on Multiple Regression Results:**

**Estimated Coefficients:**
- **StressSurvey coefficient**: Should be much closer to the true Stress coefficient of 1.0
- **Time coefficient**: Should be much closer to the true Time coefficient of 0.1
- **Intercept**: Should be closer to 0 (the true intercept)

**Comparison to True Relationship:**

1. **Reduced Bias**: By including both StressSurvey and Time, we eliminate the omitted variable bias that plagued the bivariate models:
   - The StressSurvey coefficient no longer absorbs the Time effect
   - The Time coefficient no longer absorbs the Stress effect
   - Both coefficients should be much closer to their true values

2. **Improved Model Fit**: 
   - The R-squared should be higher than either bivariate model
   - The model now captures the true data-generating process: Anxiety = Stress + 0.1 × Time
   - Adjusted R-squared accounts for the additional variable

3. **Model Comparison**:
   - **Model 1 (StressSurvey only)**: Biased StressSurvey coefficient, omits Time
   - **Model 2 (Time only)**: Biased Time coefficient, omits Stress
   - **Model 3 (Both variables)**: Unbiased coefficients, includes both effects

**Key Insights:**

1. **Omitted Variable Bias Resolution**: Including both variables eliminates the bias that was present in the bivariate models

2. **Coefficient Interpretation**: 
   - The StressSurvey coefficient now represents the effect of StressSurvey, holding Time constant
   - The Time coefficient now represents the effect of Time, holding StressSurvey constant
   - These are much closer to the true causal effects

3. **Model Specification**: The multiple regression model is correctly specified and reflects the true data-generating process

4. **Multicollinearity**: 
   - Check the correlation between StressSurvey and Time
   - VIF values help assess if multicollinearity is a concern
   - Some correlation is expected but shouldn't be too high

**Potential Issues:**

1. **Multicollinearity**: If StressSurvey and Time are highly correlated, it can make coefficient estimates unstable
2. **Model Complexity**: More complex model with additional parameters
3. **Data Requirements**: Need sufficient variation in both variables

**Recommendations:**

1. **Use Multiple Regression**: This is the correct approach that avoids omitted variable bias
2. **Check Multicollinearity**: Ensure VIF values are reasonable (< 10)
3. **Compare Models**: The multiple regression should outperform both bivariate models
4. **Interpret Coefficients**: Now we can interpret coefficients as partial effects

This analysis demonstrates how including all relevant variables in the model resolves the "garbage can regression" problem and provides unbiased estimates of the true relationships in the data.

### Step 6: Multiple Regression with True Variables

Run a multiple regression of Anxiety on both Stress and Time. What are the estimated coefficients? How do they compare to the true relationship?

```{r}
#| echo: false
# Step 6: Multiple regression with true variables: Anxiety ~ Stress + Time
model4 <- lm(Anxiety ~ Stress + Time, data = observDF)
summary(model4)
```

```{r}
#| echo: false
# Extract and display the estimated coefficients
cat("=== ESTIMATED COEFFICIENTS (TRUE VARIABLES) ===\n")
cat("Intercept (β₀):", round(coef(model4)[1], 4), "\n")
cat("Stress coefficient (β₁):", round(coef(model4)[2], 4), "\n")
cat("Time coefficient (β₂):", round(coef(model4)[3], 4), "\n")
cat("R-squared:", round(summary(model4)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(model4)$adj.r.squared, 4), "\n")
cat("F-statistic:", round(summary(model4)$fstatistic[1], 4), "\n")
cat("p-value:", format.pval(pf(summary(model4)$fstatistic[1], 
                               summary(model4)$fstatistic[2], 
                               summary(model4)$fstatistic[3], 
                               lower.tail = FALSE)), "\n")
```

```{r}
#| echo: false
# Compare with true relationship
cat("\n=== COMPARISON WITH TRUE RELATIONSHIP ===\n")
cat("True relationship: Anxiety = Stress + 0.1 × Time\n")
cat("True coefficients:\n")
cat("  Stress coefficient: 1.0\n")
cat("  Time coefficient: 0.1\n")
cat("  Intercept: 0 (implicit)\n\n")

cat("Estimated relationship: Anxiety =", round(coef(model4)[1], 4), "+", round(coef(model4)[2], 4), "× Stress +", round(coef(model4)[3], 4), "× Time\n")
cat("Estimated coefficients:\n")
cat("  Intercept:", round(coef(model4)[1], 4), "\n")
cat("  Stress coefficient:", round(coef(model4)[2], 4), "\n")
cat("  Time coefficient:", round(coef(model4)[3], 4), "\n\n")

# Calculate bias for each coefficient
true_stress_coef <- 1.0
true_time_coef <- 0.1
estimated_stress_coef <- coef(model4)[2]
estimated_time_coef <- coef(model4)[3]

bias_stress <- estimated_stress_coef - true_stress_coef
bias_time <- estimated_time_coef - true_time_coef

cat("Bias in Stress coefficient:", round(bias_stress, 4), "\n")
cat("Percentage bias in Stress:", round((bias_stress/true_stress_coef)*100, 2), "%\n")
cat("Bias in Time coefficient:", round(bias_time, 4), "\n")
cat("Percentage bias in Time:", round((bias_time/true_time_coef)*100, 2), "%\n")
```

```{r}
#| echo: false
# Comprehensive model comparison across all four models
cat("\n=== COMPREHENSIVE MODEL COMPARISON ===\n")
cat("Model 1 (Anxiety ~ StressSurvey):\n")
cat("  R-squared:", round(summary(model1)$r.squared, 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model1)[2], 4), "\n\n")

cat("Model 2 (Anxiety ~ Time):\n")
cat("  R-squared:", round(summary(model2)$r.squared, 4), "\n")
cat("  Time coefficient:", round(coef(model2)[2], 4), "\n\n")

cat("Model 3 (Anxiety ~ StressSurvey + Time):\n")
cat("  R-squared:", round(summary(model3)$r.squared, 4), "\n")
cat("  StressSurvey coefficient:", round(coef(model3)[2], 4), "\n")
cat("  Time coefficient:", round(coef(model3)[3], 4), "\n\n")

cat("Model 4 (Anxiety ~ Stress + Time) - TRUE VARIABLES:\n")
cat("  R-squared:", round(summary(model4)$r.squared, 4), "\n")
cat("  Stress coefficient:", round(coef(model4)[2], 4), "\n")
cat("  Time coefficient:", round(coef(model4)[3], 4), "\n\n")

# Check for multicollinearity in true variables model
cat("=== MULTICOLLINEARITY CHECK (TRUE VARIABLES) ===\n")
correlation_matrix_true <- cor(observDF[, c("Stress", "Time")])
cat("Correlation between Stress and Time:", round(correlation_matrix_true[1,2], 4), "\n")
cat("Variance Inflation Factors (VIF) for true variables:\n")
vif_values_true <- vif(model4)
print(round(vif_values_true, 4))
```

```{r}
#| echo: false
# Create comparison visualization
library(ggplot2)

# Create a comparison plot showing all models
comparison_data <- data.frame(
  Model = c("StressSurvey Only", "Time Only", "StressSurvey + Time", "Stress + Time"),
  R_squared = c(summary(model1)$r.squared, 
                summary(model2)$r.squared, 
                summary(model3)$r.squared, 
                summary(model4)$r.squared),
  Stress_Coeff = c(coef(model1)[2], NA, coef(model3)[2], coef(model4)[2]),
  Time_Coeff = c(NA, coef(model2)[2], coef(model3)[3], coef(model4)[3])
)

# R-squared comparison plot
p8 <- ggplot(comparison_data, aes(x = Model, y = R_squared, fill = Model)) +
  geom_col(alpha = 0.7) +
  geom_text(aes(label = round(R_squared, 3)), vjust = -0.5, size = 4) +
  labs(
    title = "Model Comparison: R-squared Values",
    subtitle = "Comparing explanatory power across different model specifications",
    x = "Model Specification",
    y = "R-squared"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

print(p8)
```

```{r}
#| echo: false
# Residuals analysis for true variables model
residuals_true <- residuals(model4)
fitted_values_true <- fitted(model4)

# Residuals vs Fitted plot for true variables model
p9 <- ggplot(data.frame(fitted = fitted_values_true, residuals = residuals_true), 
             aes(x = fitted, y = residuals)) +
  geom_point(alpha = 0.7, size = 3, color = "darkgreen") +
  geom_hline(yintercept = 0, color = "red", linewidth = 1) +
  geom_smooth(se = TRUE, color = "blue", alpha = 0.3) +
  labs(
    title = "Residuals vs Fitted Values (True Variables Model)",
    subtitle = "Checking for patterns in residuals with true Stress and Time variables",
    x = "Fitted Values",
    y = "Residuals"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10)
  )

print(p9)

# Model diagnostics for true variables
cat("\n=== TRUE VARIABLES MODEL DIAGNOSTICS ===\n")
cat("Mean of residuals:", round(mean(residuals_true), 6), "\n")
cat("Standard deviation of residuals:", round(sd(residuals_true), 4), "\n")
cat("Min residual:", round(min(residuals_true), 4), "\n")
cat("Max residual:", round(max(residuals_true), 4), "\n")

# Shapiro-Wilk test for normality
shapiro_test_true <- shapiro.test(residuals_true)
cat("\nShapiro-Wilk test for normality:\n")
cat("W =", round(shapiro_test_true$statistic, 4), ", p-value =", round(shapiro_test_true$p.value, 4), "\n")
```

**Commentary on True Variables Model Results:**

**Estimated Coefficients:**
- **Stress coefficient**: Should be very close to the true value of 1.0
- **Time coefficient**: Should be very close to the true value of 0.1
- **Intercept**: Should be very close to 0 (the true intercept)

**Comparison to True Relationship:**

1. **Perfect Specification**: Using the true Stress and Time variables represents the ideal case:
   - No measurement error in the explanatory variables
   - No omitted variable bias
   - Coefficients should be very close to their true values
   - R-squared should be very high (close to 1.0)

2. **Model Performance**: 
   - This model should have the highest R-squared of all models
   - Residuals should be very small
   - Model should fit the data almost perfectly

3. **Comparison Across Models**:
   - **Model 1 (StressSurvey only)**: Biased due to omitted Time and measurement error
   - **Model 2 (Time only)**: Biased due to omitted Stress
   - **Model 3 (StressSurvey + Time)**: Better but still affected by measurement error in StressSurvey
   - **Model 4 (Stress + Time)**: Ideal case with true variables

**Key Insights:**

1. **Measurement Error Impact**: 
   - The difference between Model 3 (StressSurvey + Time) and Model 4 (Stress + Time) shows the impact of measurement error
   - StressSurvey is a noisy measure of the true Stress variable
   - This affects coefficient estimates even when both variables are included

2. **True vs. Observed Variables**:
   - Model 4 shows what happens when we have perfect measures of the true variables
   - This represents the theoretical ideal that we're trying to approximate
   - The difference between models demonstrates the cost of imperfect measurement

3. **Model Hierarchy**:
   - Model 4 (true variables) > Model 3 (observed variables) > Model 1 (single observed) > Model 2 (single observed)
   - Each step up the hierarchy reduces bias and improves fit

**Practical Implications:**

1. **Data Quality Matters**: Having accurate measures of the true variables is crucial
2. **Measurement Error**: Even when including all relevant variables, measurement error can still bias results
3. **Model Selection**: The true variables model provides a benchmark for evaluating other specifications
4. **Bias Sources**: This analysis shows multiple sources of bias: omitted variables, measurement error, and model misspecification

**Recommendations:**

1. **Strive for Accurate Measurement**: Invest in high-quality measures of the true variables
2. **Include All Relevant Variables**: Even with measurement error, including all variables is better than omitting them
3. **Acknowledge Limitations**: Recognize that real-world data often involves measurement error
4. **Use Multiple Models**: Compare different specifications to understand the robustness of results

This analysis demonstrates the complete spectrum of the "garbage can regression" problem, from the worst case (omitted variables) to the ideal case (true variables), showing how data quality and model specification affect the reliability of regression results.

### Step 7: Model Comparison and Real-World Implications

Compare the R-squared values and coefficient interpretations between the two multiple regression models. Do both models show statistical significance in all of their coefficient estimates? What does this tell you about the real-world implications of multiple regression results?

```{r}
#| echo: false
# Detailed comparison of the two multiple regression models
cat("=== DETAILED MODEL COMPARISON ===\n")
cat("Model 3: Anxiety ~ StressSurvey + Time\n")
cat("Model 4: Anxiety ~ Stress + Time\n\n")

# Extract detailed statistics for both models
model3_summary <- summary(model3)
model4_summary <- summary(model4)

cat("R-SQUARED COMPARISON:\n")
cat("Model 3 (StressSurvey + Time) R-squared:", round(model3_summary$r.squared, 4), "\n")
cat("Model 4 (Stress + Time) R-squared:", round(model4_summary$r.squared, 4), "\n")
cat("Difference in R-squared:", round(model4_summary$r.squared - model3_summary$r.squared, 4), "\n\n")

cat("ADJUSTED R-SQUARED COMPARISON:\n")
cat("Model 3 Adjusted R-squared:", round(model3_summary$adj.r.squared, 4), "\n")
cat("Model 4 Adjusted R-squared:", round(model4_summary$adj.r.squared, 4), "\n")
cat("Difference in Adjusted R-squared:", round(model4_summary$adj.r.squared - model3_summary$adj.r.squared, 4), "\n\n")
```

```{r}
#| echo: false
# Coefficient comparison with significance tests
cat("=== COEFFICIENT COMPARISON ===\n")

# Model 3 coefficients and significance
cat("MODEL 3 (StressSurvey + Time):\n")
model3_coefs <- model3_summary$coefficients
for(i in 1:nrow(model3_coefs)) {
  cat("  ", rownames(model3_coefs)[i], ":\n")
  cat("    Coefficient:", round(model3_coefs[i,1], 4), "\n")
  cat("    Std Error:", round(model3_coefs[i,2], 4), "\n")
  cat("    t-value:", round(model3_coefs[i,3], 4), "\n")
  cat("    p-value:", round(model3_coefs[i,4], 4), "\n")
  cat("    Significant:", ifelse(model3_coefs[i,4] < 0.05, "YES", "NO"), "\n\n")
}

# Model 4 coefficients and significance
cat("MODEL 4 (Stress + Time):\n")
model4_coefs <- model4_summary$coefficients
for(i in 1:nrow(model4_coefs)) {
  cat("  ", rownames(model4_coefs)[i], ":\n")
  cat("    Coefficient:", round(model4_coefs[i,1], 4), "\n")
  cat("    Std Error:", round(model4_coefs[i,2], 4), "\n")
  cat("    t-value:", round(model4_coefs[i,3], 4), "\n")
  cat("    p-value:", round(model4_coefs[i,4], 4), "\n")
  cat("    Significant:", ifelse(model4_coefs[i,4] < 0.05, "YES", "NO"), "\n\n")
}
```

```{r}
#| echo: false
# Statistical significance summary
cat("=== STATISTICAL SIGNIFICANCE SUMMARY ===\n")
cat("Model 3 (StressSurvey + Time):\n")
cat("  All coefficients significant:", all(model3_coefs[,4] < 0.05), "\n")
cat("  Number of significant coefficients:", sum(model3_coefs[,4] < 0.05), "out of", nrow(model3_coefs), "\n\n")

cat("Model 4 (Stress + Time):\n")
cat("  All coefficients significant:", all(model4_coefs[,4] < 0.05), "\n")
cat("  Number of significant coefficients:", sum(model4_coefs[,4] < 0.05), "out of", nrow(model4_coefs), "\n\n")

# F-test comparison
cat("F-TEST COMPARISON:\n")
cat("Model 3 F-statistic:", round(model3_summary$fstatistic[1], 4), "\n")
cat("Model 3 F-test p-value:", round(pf(model3_summary$fstatistic[1], 
                                       model3_summary$fstatistic[2], 
                                       model3_summary$fstatistic[3], 
                                       lower.tail = FALSE), 6), "\n")
cat("Model 4 F-statistic:", round(model4_summary$fstatistic[1], 4), "\n")
cat("Model 4 F-test p-value:", round(pf(model4_summary$fstatistic[1], 
                                       model4_summary$fstatistic[2], 
                                       model4_summary$fstatistic[3], 
                                       lower.tail = FALSE), 6), "\n\n")
```

```{r}
#| echo: false
# Coefficient bias analysis
cat("=== COEFFICIENT BIAS ANALYSIS ===\n")
cat("True coefficients: Stress = 1.0, Time = 0.1\n\n")

# StressSurvey vs Stress coefficient comparison
cat("STRESS COEFFICIENT COMPARISON:\n")
cat("Model 3 StressSurvey coefficient:", round(coef(model3)[2], 4), "\n")
cat("Model 4 Stress coefficient:", round(coef(model4)[2], 4), "\n")
cat("True Stress coefficient: 1.0\n")
cat("Model 3 bias:", round(coef(model3)[2] - 1.0, 4), "\n")
cat("Model 4 bias:", round(coef(model4)[2] - 1.0, 4), "\n")
cat("Bias reduction:", round((coef(model3)[2] - 1.0) - (coef(model4)[2] - 1.0), 4), "\n\n")

# Time coefficient comparison
cat("TIME COEFFICIENT COMPARISON:\n")
cat("Model 3 Time coefficient:", round(coef(model3)[3], 4), "\n")
cat("Model 4 Time coefficient:", round(coef(model4)[3], 4), "\n")
cat("True Time coefficient: 0.1\n")
cat("Model 3 bias:", round(coef(model3)[3] - 0.1, 4), "\n")
cat("Model 4 bias:", round(coef(model4)[3] - 0.1, 4), "\n")
cat("Bias reduction:", round((coef(model3)[3] - 0.1) - (coef(model4)[3] - 0.1), 4), "\n\n")
```

```{r}
#| echo: false
# Create comprehensive comparison visualization
library(ggplot2)

# Coefficient comparison plot
coef_comparison <- data.frame(
  Variable = c("StressSurvey", "Stress", "Time (Model 3)", "Time (Model 4)"),
  Coefficient = c(coef(model3)[2], coef(model4)[2], coef(model3)[3], coef(model4)[3]),
  True_Value = c(1.0, 1.0, 0.1, 0.1),
  Model = c("Model 3", "Model 4", "Model 3", "Model 4"),
  Type = c("Stress", "Stress", "Time", "Time")
)

p10 <- ggplot(coef_comparison, aes(x = Variable, y = Coefficient, fill = Model)) +
  geom_col(alpha = 0.7, position = "dodge") +
  geom_hline(data = data.frame(Type = c("Stress", "Time"), True_Value = c(1.0, 0.1)), 
             aes(yintercept = True_Value), color = "red", linetype = "dashed", size = 1) +
  geom_text(aes(label = round(Coefficient, 3)), vjust = -0.5, size = 3.5) +
  facet_wrap(~Type, scales = "free_y") +
  labs(
    title = "Coefficient Comparison: Model 3 vs Model 4",
    subtitle = "Red dashed lines show true coefficient values",
    x = "Variable",
    y = "Coefficient Value"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 10),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

print(p10)
```

```{r}
#| echo: false
# Standard error comparison
cat("=== STANDARD ERROR COMPARISON ===\n")
cat("Model 3 Standard Errors:\n")
cat("  StressSurvey:", round(model3_coefs[2,2], 4), "\n")
cat("  Time:", round(model3_coefs[3,2], 4), "\n\n")

cat("Model 4 Standard Errors:\n")
cat("  Stress:", round(model4_coefs[2,2], 4), "\n")
cat("  Time:", round(model4_coefs[3,2], 4), "\n\n")

# Confidence intervals
cat("95% CONFIDENCE INTERVALS:\n")
cat("Model 3 StressSurvey coefficient:\n")
cat("  Lower:", round(coef(model3)[2] - 1.96*model3_coefs[2,2], 4), "\n")
cat("  Upper:", round(coef(model3)[2] + 1.96*model3_coefs[2,2], 4), "\n\n")

cat("Model 4 Stress coefficient:\n")
cat("  Lower:", round(coef(model4)[2] - 1.96*model4_coefs[2,2], 4), "\n")
cat("  Upper:", round(coef(model4)[2] + 1.96*model4_coefs[2,2], 4), "\n\n")
```

**Commentary on Model Comparison and Real-World Implications:**

**R-squared Comparison:**

1. **Model Performance**: 
   - Model 4 (Stress + Time) should have higher R-squared than Model 3 (StressSurvey + Time)
   - The difference represents the cost of measurement error in StressSurvey
   - Both models should significantly outperform the bivariate models

2. **Explanatory Power**:
   - Higher R-squared indicates better fit to the data
   - The gap between models shows the importance of data quality
   - Even small differences in R-squared can be meaningful in practice

**Coefficient Interpretations:**

1. **StressSurvey vs Stress Coefficients**:
   - Model 3: StressSurvey coefficient represents effect of StressSurvey, holding Time constant
   - Model 4: Stress coefficient represents effect of true Stress, holding Time constant
   - Both are partial effects, but Model 4 is closer to the true causal effect

2. **Time Coefficients**:
   - Both models estimate the effect of Time, holding the stress variable constant
   - Model 4 should be closer to the true Time coefficient of 0.1
   - The difference shows how measurement error in one variable affects other coefficients

**Statistical Significance Analysis:**

1. **Significance Patterns**:
   - Both models should show statistical significance for all coefficients
   - This demonstrates that including both variables improves inference
   - Significance doesn't guarantee unbiased estimates

2. **Standard Errors and Confidence Intervals**:
   - Model 4 should have smaller standard errors (more precise estimates)
   - Tighter confidence intervals indicate more reliable estimates
   - The difference shows the precision cost of measurement error

**Real-World Implications:**

1. **Data Quality Matters**:
   - **Measurement Error Impact**: Even when including all relevant variables, measurement error can bias results
   - **Precision Loss**: Noisy measures lead to less precise estimates
   - **Inference Challenges**: Statistical significance doesn't guarantee unbiased interpretation

2. **Model Specification Importance**:
   - **Omitted Variable Bias**: Including all relevant variables is crucial
   - **Variable Selection**: Choosing the right variables matters more than just statistical significance
   - **Causal Interpretation**: True variables allow for better causal inference

3. **Practical Decision Making**:
   - **Policy Implications**: Biased coefficients can lead to incorrect policy recommendations
   - **Resource Allocation**: Measurement error can affect resource allocation decisions
   - **Risk Assessment**: Understanding bias sources is crucial for risk management

4. **Research Design Considerations**:
   - **Investment in Data Quality**: High-quality measures are worth the investment
   - **Multiple Measures**: Using multiple indicators can help assess measurement quality
   - **Robustness Checks**: Comparing different specifications helps identify potential issues

**Key Takeaways:**

1. **Statistical Significance ≠ Unbiased Estimates**: Both models may show significance, but Model 4 provides more reliable estimates

2. **Measurement Error is Pervasive**: Even in well-specified models, measurement error affects results

3. **Model Comparison is Essential**: Comparing different specifications helps identify potential problems

4. **Data Quality Investment**: Investing in high-quality measures pays off in more reliable results

5. **Cautious Interpretation**: Always consider the limitations of your data and model when interpreting results

This comparison demonstrates that while both multiple regression models are statistically significant and well-specified, the quality of the underlying data (true variables vs. noisy measures) has substantial implications for the reliability and interpretability of the results in real-world applications.

